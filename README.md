

# GarmageJigsaw



<p align="center"><img src="assest/images/garmagejigsaw.png" width="100%"></p>

> This project is a component of **[GarmageNet](https://github.com/Style3D/garmagenet-impl)**, and mainly includes:
>
> - processing pipelines for generated Garmage garments;
> - the stitch prediction module  **GarmageJigsaw**, a dedicated module that leverages Garmageâ€™s embedded 2D silhouettes and 3D spatial cues to robustly infer vertex-wise sewing correspondences;
> - post-processing used to integrate into **[Style3D Studio](https://studio.style3d.com/)**.



## ðŸ”¨ Installation

**Tested Environment:** `Ubuntu 22.04` + `CUDA 11.8` + `Python 3.8` + `PyTorch 1.10`

Clone the repo.

Install PyTorch and other dependencies:

```bash
conda create -n garmagejigsaw python=3.8
pip install -r requirements.txt
conda install cudatoolkit=11.8
pip install chamferdist
```



## ðŸŽ¡ Training

### Data Process

Download dataset refer to the **Data Preparation** part in the **[GarmageNet](https://github.com/Style3D/garmagenet-impl)**.

Preprocess training data:

```bash
# Preprocess Garmageset raw objs.
python data_process/garmageset/preprocess_garmageset.py \
	--objs_dir <garmageset-root>/raw \
	--output_root <garmageset-root>/garmagejigsaw_data/preprocessed_jigsaw_train

# Prepare datalist
python data_process/garmageset/get_dataset_split.py \
	--dataset_dir <garmageset-root>/garmagejigsaw_data/preprocessed_jigsaw_train \
    --output_dir <garmageset-root>/garmagejigsaw_data/datalist
```

###  GarmageJigsaw Training

Update the following lines in the config file: **experiments/train/train.yaml**

```yaml
DATA:
  DATA_DIR: "<garmageset-root>/garmagejigsaw_data/preprocessed_jigsaw_train"
  DATASET_SPLIT_DIR: "<garmageset-root>/garmagejigsaw_data/datalist"
```

Train GarmageJigsaw.

```bash
python garmage_jigsaw/train_garmage_jigsaw.py \
	--cfg experiments/train/train.yaml
```



## ðŸš€Usage

###  **Generated Garmage processing.**

The **GarmageNet generate output** like following (for example sketch condition generation):

```bash
<garmagenet-output-dir>
â””â”€â”€ sketch_cond
â”‚Â Â  â”œâ”€â”€ <uuid_1>.pkl				# garmage
â”‚Â Â  â”œâ”€â”€ <uuid_1>_geo_img.png		# visualize garmage as 2D image panel-wise
â”‚Â Â  â”œâ”€â”€ <uuid_1>_pointcloud.png		# visualize garmage in 3D
â”‚Â Â  â”œâ”€â”€ ...
â”‚Â Â  â”œâ”€â”€ <uuid_n>.pkl
â”‚Â Â  â”œâ”€â”€ <uuid_n>_geo_img.png
â”‚Â Â  â””â”€â”€ <uuid_n>_pointcloud.png
```

Extract boundary points and vectorized pattern of Garmage generated by GarmageNet.

```bash
python garmage_jigsaw/extract_boundary_pts.py \
    --data_dir <garmagenet-output-dir>/sketch_cond \
    --delta 0.012 \
    --shape_dedup False
```
After processing, the boundary extraction results like following.

```bash
<garmagenet-output-dir>
â””â”€â”€ sketch_cond_extracted
â”‚Â Â  â”œâ”€â”€ <uuid_1>
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ piece_1.obj		# boundary points of panel 1
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ...
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ piece_n.obj		# boundary points of panel n
â”‚Â Â  â”‚Â Â  â””â”€â”€ annotation
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ garment_<uuid_1>.json	# vectorized pattern (without sewing)
â”‚Â Â  â”œâ”€â”€ ...
â”‚Â Â  â”œâ”€â”€ <uuid_n>
```

<p align="center"><img src="assest/images/postprocess_extract_boundary.png" width="100%"></p>

### GarmageJigsaw Inference

Recovery point-wise sewing of Garmage, and merge it into vectorized pattern to get the sewing pattern.

```bash
python garmage_jigsaw/inference_ps2es.py \
    --cfg experiments/train/train.yaml \
    --weight <GarmageJigsaw-ckpt> \
    --data_dir <garmagenet-output-dir>/sketch_cond_extracted \
    --update_dis_iter 1 --inf_noise_strength 6
```

The GarmageJigsaw outputs like following.

```bash
<garmagenet-output-dir>
â””â”€â”€ garmagejigsaw_output
â”‚Â Â  â”œâ”€â”€ <uuid_1>
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ garment.json		# vectorized sewing pattern
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ orig_data.pkl		# garmage
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ vis_comp.html		# visualization 
â”‚Â Â  â”‚Â Â  â””â”€â”€ vis_resource.pkl
â”‚Â Â  â”œâ”€â”€ ...
â”‚Â Â  â”œâ”€â”€ <uuid_n>
```

<p align="center"><img src="assest/images/postprocess_GarmageJigsaw_output.png" width="100%"></p>

â€‹	*For high-quality generation results, `--delta` can be set to **0.008** and `--inf_noise_strength` can be set to **3**.*



## ðŸ‘• Integrating to [Style3D Studio](https://studio.style3d.com/)

As above, GarmageJigsaw outputs **vectorized sewing patterns** in JSON format (`garment.json`) while the draping initializations are provided as Garmage PKL (`orig_data.pkl`). To integrate the results into existing garment modeling pipeline, we need to triangulate the sewing pattern and transfer Garmage into per-vertex location. 

### Triangulation

Copy the code of **`garmage_jigsaw/post_processing/json_2_sproj.py`** to the Style3D Studio script window. Change `data_root` to `<garmagenet-output-dir>/garmagejigsaw_output` and run the script.

<p align="center"><img src="assest/images/postprocess_json_2_sproj.png" width=100%"></p>

------

Export the triangulated mesh of the flat pattern in `.obj` format from the `.sproj` file *(Run in **IDE**)*.

```bash
python garmage_jigsaw/post_processing/sproj_2_json_obj.py \
	--data_root <garmagenet-output-dir>/arrangement
```

<p align="center"><img src="assest/images/postprocess_sproj_2_json_obj.png" width=100%"></p>

### Transfer Draping Initialization from Garmage to Triangle Mesh

Querying per-vertex 3D location from Garmage by running the following script from command line:
```
python garmage_jigsaw/post_processing/arrangement.py \
	--data_dir <garmagenet-output-dir>/arrangement
```

<p align="center"><img src="assest/images/postprocess_arrangement.png" width=100%"></p>

------

Import the initialization results back to Style3D Studio by running `garmage_jigsaw/post_processing/arrangement_2_sproj.py` from Style3D Studio's script environment. Remember to change the `data_root` to the output directory (e.g. `<garmagenet-output-dir>/arrangement`) in the previous step. 

You should copy the code of `**garmage_jigsaw/post_processing/arrangement_2_sproj.py**` to the Style3D Studio script window. 

Then change `data_root` to the  and run script by press the button shown in image below.

<p align="center"><img src="assest/images/postprocess_arrangement_2_sproj.png" width=100%"></p>



## ðŸŒŸ Acknowledgement

We extend our sincere gratitude to [Jigsaw](https://github.com/Jiaxin-Lu/Jigsaw) and [PuzzleFusion++](https://github.com/eric-zqwang/puzzlefusion-plusplus) who laid the foundation for GarmageJigsaw.



## ðŸ“ƒ License

This project is licensed under the CC BY-NC-ND 4.0 License - see the [LICENSE](LICENSE) file for details.



## ðŸ“š Citation

If you find our work useful for your research, please cite our work:

```
@article{li2025garmagenet,
  title={GarmageNet: A Multimodal Generative Framework for Sewing Pattern Design and Generic Garment Modeling},
  author={Li, Siran and Liu, Ruiyang and Liu, Chen and Wang, Zhendong and He, Gaofeng and Li, Yong-Lu and Jin, Xiaogang and Wang, Huamin},
  journal={ACM Transactions on Graphics (TOG)},
  volume={44},
  number={6},
  pages={1--23},
  year={2025},
  publisher={ACM New York, NY, USA}
}
```

